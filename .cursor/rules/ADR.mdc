---
description: Architectural Decision Records
globs:
alwaysApply: false
---

# Architecture Decision Log

<!--
ADR_AGENT_PROTOCOL v1.0

You (the agent) manage this file as the single source of truth for all ADRs.

INVARIANTS
- Keep this exact file structure and headings.
- All ADR entries use H2 headings: "## ADR-XXXX — <Title>" (4-digit zero-padded ID).
- Allowed Status values: Proposed | Accepted | Superseded
- Date format: YYYY-MM-DD
- New entries must be appended to the END of the file.
- The Index table between the INDEX markers must always reflect the latest state and be sorted by ID desc (newest on top).
- Each ADR MUST contain: Date, Status, Owner, Context, Decision, Consequences.
- Each ADR must include an explicit anchor `<a id="adr-XXXX"></a>` so links remain stable.

HOW TO ADD A NEW ADR
1) Read the whole file.
2) Compute next ID:
   - Scan for headings matching: ^## ADR-(\d{4}) — .+$
   - next_id = (max captured number) + 1, left-pad to 4 digits.
3) Create a new ADR section using the “New ADR Entry Template” below.
   - Place it AFTER the last ADR section in the file.
   - Add an `<a id="adr-XXXX"></a>` line immediately below the heading.
4) Update the Index (between the INDEX markers):
   - Insert/replace the row for this ADR keeping the table sorted by ID descending.
   - Title in the Index MUST link to the anchor: [<Title>](#adr-XXXX)
   - If this ADR supersedes another: set “Supersedes” in this row, and update that older ADR:
       a) Change its Status to “Superseded”
       b) Add “Superseded by: ADR-XXXX” in its Consequences block
       c) Update the older ADR’s Index row “Superseded by” column to ADR-XXXX
5) Validate before saving:
   - Exactly one heading exists for ADR-XXXX
   - All required fields are present and non-empty
   - Index contains a row for ADR-XXXX and remains properly sorted
6) Concurrency resolution:
   - If a merge conflict or duplicate ID is detected after reading: recompute next_id from the current file state, rename your heading, anchor, and Index row accordingly, and retry once.

COMMIT MESSAGE SUGGESTION
- "ADR-XXXX: <Short Title> — <Status>"

END ADR_AGENT_PROTOCOL
-->

## Index

<!-- BEGIN:ADR_INDEX -->

| ID   | Title                                                        | Date       | Status   | Supersedes | Superseded by |
| ---- | ------------------------------------------------------------ | ---------- | -------- | ---------- | ------------- |
| 0004 | [Comprehensive Environment Configuration System](#adr-0004)  | 2025-01-15 | Accepted | —          | —             |
| 0003 | [MVP Orchestration and Tooling Choices](#adr-0003)           | 2025-09-11 | Accepted | —          | —             |
| 0002 | [Event-Driven Broker Architecture with Firestore](#adr-0002) | 2025-01-27 | Accepted | —          | —             |
| 0001 | [Agent-Focused Repository Structure](#adr-0001)              | 2025-01-27 | Accepted | —          | —             |

<!-- END:ADR_INDEX -->

---

## ADR-0004 — Comprehensive Environment Configuration System

<a id="adr-0004"></a>
**Date**: 2025-01-15
**Status**: Accepted
**Owner**: AI Agent

### Context

The Autopiloot system integrates with 8+ external services requiring API credentials: OpenAI (GPT-4.1), AssemblyAI (transcription), YouTube Data API (discovery), Slack (notifications), Google Drive & Sheets (storage), Zep (GraphRAG), and optional Langfuse (observability). Manual environment setup across development and production environments is error-prone, lacks validation, and poses security risks. Previous approaches with simple .env files led to deployment failures due to missing or incorrectly formatted variables.

### Alternatives

- **Simple .env files only**: No validation, unclear required vs optional variables, prone to deployment errors with cryptic failure messages
- **Hard-coded configuration**: Major security risk, no environment flexibility, violates 12-factor app principles
- **Complex configuration frameworks** (e.g., Hydra, OmegaConf): Overkill for MVP scope, unnecessary dependencies, learning curve overhead
- **Environment-specific config files**: Risk of committing secrets, configuration drift between environments, maintenance burden
- **Cloud provider secret management**: Platform lock-in, additional complexity for development environment, cost for MVP

### Decision

Implement comprehensive environment configuration system with structured validation and developer experience focus:

**Core Components:**
- `env.template` - Complete variable reference without secrets, serves as documentation
- `config/env_loader.py` - Validation module with type checking, clear error messages, and service-specific getters
- Production-ready error handling with graceful fallback to system environment variables
- Complete test coverage (17 test cases) covering validation scenarios, edge cases, and error conditions
- `ENVIRONMENT.md` - Step-by-step setup guide with API key acquisition instructions and troubleshooting

**Key Features:**
- Service-specific API key access (`get_api_key('openai')`, `get_api_key('slack')`, etc.)
- Required vs optional variable distinction with sensible defaults
- File existence validation for Google service account credentials
- Clear separation between development (.env) and production (system vars) configuration
- Comprehensive error messages guiding developers to resolution

### Consequences

- **Pros**: Eliminates deployment configuration errors, provides immediate validation feedback, ensures secure credential handling, comprehensive documentation reduces onboarding time, production-ready error handling, 100% test coverage prevents regressions, service-specific getters prevent API key mix-ups
- **Cons / risks**: Additional complexity over simple .env approach, requires initial setup documentation maintenance, dependency on python-dotenv package, potential over-engineering for simple use cases
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- All 17 environment loader tests pass with 100% coverage of validation scenarios
- No secrets committed to repository (env.template verified to contain only placeholder values)
- Clear error messages tested for all missing/invalid variable scenarios
- Complete documentation verified with step-by-step API key acquisition for all services
- Service-specific getters tested to prevent cross-service API key usage errors
- Production deployment tested with system environment variables (no .env file)

## ADR-0003 — MVP Orchestration and Tooling Choices

<a id="adr-0003"></a>
**Date**: 2025-09-11
**Status**: Accepted
**Owner**: AI Agent

### Context

Autopiloot v1 targets an MVP for LinkedIn-first content creators (6-figure revenue entrepreneurs) requiring automated YouTube content processing pipeline. Core requirements: daily video discovery from @AlexHormozi, high-quality transcription with cost controls ($5/day budget), actionable coaching-style summaries, and internal operational alerting. Infrastructure must minimize operational complexity while ensuring reliability, cost visibility, and audit trails for business intelligence.

### Alternatives

- **GitHub Actions for scheduling**: External dependency outside Google Cloud ecosystem, timezone/DST handling complexity, less direct integration with Firestore triggers, additional authentication overhead
- **Direct video scraping vs YouTube Data API**: Higher brittleness, maintenance burden, rate limiting challenges, risk of breaking with platform changes, potential ToS violations
- **Custom vector store vs Zep**: Significant development overhead, time-to-market delay, maintenance burden, feature parity challenges, no GraphRAG capabilities
- **Open client ingestion vs controlled workflow**: Increased security surface area, data quality concerns, audit complexity, inappropriate for MVP scope
- **Custom transcription vs AssemblyAI**: Development complexity, quality concerns, no speaker diarization, cost optimization challenges

### Decision

Implement minimal-complexity cloud-native architecture optimized for reliability and observability:

**Scheduling & Orchestration:**
- Firebase Functions v2 scheduled functions with Cloud Scheduler at 01:00 Europe/Amsterdam (CET/CEST with automatic DST handling)
- Event-driven budget alerts triggered by Firestore document writes to `transcripts/{video_id}`
- Dead-letter queue pattern for failed operations with exponential backoff

**Data Architecture:**
- Firestore as primary event broker and system of record with collections: `videos`, `transcripts`, `summaries`, `jobs/transcription`, `costs_daily`, `audit_logs`, `jobs_deadletter`
- Server-only security rules (no client access) using Firebase Admin SDK for all data operations
- Audit logging for all critical operations with structured metadata

**External Services Integration:**
- YouTube Data API v3 for discovery with `lastPublishedAt` checkpoint persistence and quota exhaustion fallback/resume
- AssemblyAI for transcription with strict 70-minute video duration cap (4200 seconds)
- OpenAI GPT-4.1 (temperature 0.2, ~1500 token output) for coaching-style short summaries with `prompt_version: v1` tracking
- Zep collection `autopiloot_guidelines` for GraphRAG storage with explicit metadata linkage to source transcripts
- Slack API for internal alerts to `#ops-autopiloot` channel with 1 alert/type/hour throttling

### Consequences

- **Pros**: Minimal operational complexity and maintenance overhead, clear reliability measures with built-in monitoring, transparent cost visibility with automated budget controls, reproducible summary generation with version tracking, seamless timezone handling, strong audit trail for business intelligence
- **Cons / risks**: API quota limits may delay processing during high-volume periods, external service dependencies (AssemblyAI, Zep) create failure points, no end-user interface limits MVP feedback, vendor lock-in to Google Cloud ecosystem, limited to single channel initially
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- Scheduled function execution logged daily with success/failure metrics and runtime duration tracking
- Budget alert system verified to trigger at 80% of daily $5 transcription limit using `costs_daily/{YYYY-MM-DD}` aggregation
- Summary generation verified to include `prompt_version: v1` metadata and bidirectional Zep document linkage
- Dead-letter queue population monitored for repeated failures with automatic escalation
- Firestore indexes configured for efficient querying of video status progression and cost aggregation
- Audit logs created for all key operations: video discovery, transcription submission, summary generation, cost threshold breaches

## New ADR Entry Template (copy for each new decision)

> Replace placeholders, keep section headers. Keep prose concise.

```

## ADR-XXXX — \<Short, specific title>

<a id="adr-XXXX"></a>
**Date**: YYYY-MM-DD
**Status**: Proposed | Accepted | Superseded
**Owner**: <Name>

### Context

<1–3 sentences: what changed or what forces drive this decision now>

### Alternatives

<Quick bullet list of alternatives considered, and why they were rejected.>

### Decision

\<Single clear decision in active voice; make it testable/verifiable>

### Consequences

* **Pros**: \<benefit 1>, \<benefit 2>
* **Cons / risks**: \<cost 1>, \<risk 1>
* **Supersedes**: ADR-NNNN (if any)
* **Superseded by**: ADR-MMMM (filled later if replaced)

### (Optional) Compliance / Verification

\<How we’ll check this is honored: tests, checks, fitness functions, runbooks>

```

---

## ADR-0002 — Event-Driven Broker Architecture with Firestore

<a id="adr-0002"></a>
**Date**: 2025-01-27  
**Status**: Accepted  
**Owner**: AI Agent

### Context

Modern full-stack applications require consistent data state between frontend and backend components. Traditional request-response patterns create tight coupling and require complex state synchronization logic. Real-time applications need immediate UI updates when data changes, regardless of the source of the change.

### Alternatives

- **Direct API communication**: Backend returns data directly to frontend, requires manual state management
- **Event streaming with external broker**: Use services like Redis Pub/Sub or RabbitMQ, adds infrastructure complexity
- **WebSocket connections**: Real-time but requires connection management and doesn't persist data
- **Firestore as event-driven broker**: Leverages built-in real-time capabilities and acts as single source of truth

### Decision

Implement event-driven broker architecture where Firestore serves as both the data store and event broker:

- All data mutations flow through Firestore exclusively
- Backend functions save data to Firestore without returning responses to frontend
- Frontend subscribes to Firestore collections/documents using hooks for real-time updates
- Firestore acts as the single source of truth for both backend and frontend
- UI updates automatically through Firestore real-time listeners

### Consequences

- **Pros**: Eliminates data synchronization issues, automatic real-time updates, reduced coupling between frontend and backend, simplified state management, leverages Firebase's built-in capabilities
- **Cons / risks**: Increased Firestore read operations, requires proper security rules design, potential data consistency challenges with complex operations, network dependency for all data access
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

Backend functions must only perform Firestore writes without returning data responses. Frontend components must use Firestore hooks (useFirestore, real-time listeners) for all data access. No direct API data responses to frontend. All data mutations trigger UI updates through Firestore change events.

---

## ADR-0001 — Agent-Focused Repository Structure

<a id="adr-0001"></a>
**Date**: 2025-01-27
**Status**: Accepted
**Owner**: AI Agent

### Context

The repository has evolved from a full-stack Firebase template to focus specifically on AI agent development and management. The original frontend and backend directories are no longer present, and the repository now contains agent-specific configuration, documentation, and task templates.

### Alternatives

- **Maintain full-stack structure**: Keep frontend and backend directories even if unused, adds complexity
- **Create separate agent repository**: Move agent files to a new repository, loses Firebase configuration context
- **Hybrid structure**: Keep both full-stack and agent components, creates confusion about primary purpose
- **Agent-focused structure**: Simplify to focus on agent development with Firebase as supporting infrastructure

### Decision

Implement agent-focused repository structure:

- `/agents/` - Primary directory containing all agent-related files and configuration
- Firebase configuration files (`firebase.json`, `firestore.rules`, `storage.rules`) at the agents level
- Agent documentation and rules in `.cursor/rules/` subdirectory
- Task templates in `tasks/` subdirectory
- Remove references to frontend and backend directories that no longer exist

### Consequences

- **Pros**: Clear focus on agent development, simplified structure, Firebase configuration remains available for agent backend needs, easier maintenance
- **Cons / risks**: Loss of full-stack template capabilities, may need to recreate frontend/backend if needed later, Firebase configuration references non-existent backend directory
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

Repository structure contains only agent-related files. Firebase configuration is updated to reflect actual directory structure. No references to non-existent frontend or backend directories in documentation.

---
