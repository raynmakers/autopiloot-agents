---
description: "Build reasoning adapter to generate answers from fused hybrid retrieval context"
globs: []
alwaysApply: false
---

id: "TASK-RAG-0072F"
title: "Create answer_with_hybrid_context tool (LLM adapter)"
status: "completed"
priority: "P1"
labels: ["reasoning", "summarizer_agent", "llm"]
dependencies: ["TASK-RAG-0072E"]
created: "2025-10-12"
completed: "2025-10-13"

# 1) High-Level Objective

Turn fused results into prompt-ready context and call the LLM with structured output.

# 2) End State

- File: `summarizer_agent/tools/answer_with_hybrid_context.py`
- JSON response includes final answer, citations (video_id, chunk_id), and source breakdown.

# 3) Low-Level Steps

1. Inputs: `query`, `filters`, `top_k`, `max_tokens_per_source`.
2. Call `hybrid_retrieval`; trim/dedupe context; balance per-source contributions.
3. Evidence alignment: highlight overlaps; conflict resolution using trust hierarchy and optional BigQuery verification.
4. Invoke LLM with structured outputs (schema-enforced); return JSON with citations.

# 4) Acceptance Criteria

- Returns valid JSON with answer, citations, and metrics.
- Handles conflicting signals with deterministic rules.

# 5) Testing Strategy

- Mock hybrid_retrieval and LLM; test alignment/trim logic and JSON schema adherence.

---

# Implementation Summary

## ‚úÖ Deliverable

**File**: `summarizer_agent/tools/answer_with_hybrid_context.py` (335 lines)
**Test File**: `tests/summarizer_tools/test_answer_with_hybrid_context_coverage.py` (14 comprehensive tests)
**Configuration**: LLM task config added to `config/settings.yaml` (rag_answer_question)

### Features Implemented

1. ‚úÖ **Hybrid Retrieval Integration**: Calls HybridRetrieval to get fused Zep + OpenSearch results
2. ‚úÖ **Context Balancing**: Prevents single-source bias with configurable max tokens per source (default: 4000)
3. ‚úÖ **Evidence Alignment**: Detects multi-source chunks for high-confidence evidence
4. ‚úÖ **Trust Hierarchy**: Prioritizes multi-source > semantic (Zep) > keyword (OpenSearch)
5. ‚úÖ **Conflict Resolution**: Deterministic rules based on evidence overlap ratio
6. ‚úÖ **Structured Outputs**: OpenAI Structured Outputs with strict JSON schema enforcement
7. ‚úÖ **Citation Tracking**: Comprehensive citations with video titles, chunk IDs, and source types
8. ‚úÖ **Quality Metrics**: Confidence assessment, evidence quality, and limitation reporting

### Architecture

```python
AnswerWithHybridContext(
    query: str,                          # User question
    top_k: int = 10,                     # Results to retrieve
    max_tokens_per_source: int = 4000,   # Balance limit per source
    channel_id: Optional[str] = None,    # Filter by channel
    min_published_date: Optional[str] = None,  # Date range filter
    max_published_date: Optional[str] = None
)
```

**Process Flow:**
1. Call HybridRetrieval to get fused results from Zep + OpenSearch
2. Balance context per source (prevent single-source bias)
3. Detect evidence overlaps (multi-source = high confidence)
4. Build prompt with confidence markers and trust guidance
5. Invoke LLM with structured outputs (JSON schema enforced)
6. Return answer with citations and quality metrics

### Trust Hierarchy for Conflict Resolution

**Confidence Levels:**
- **HIGH** (‚â•50% multi-source): Prioritize multi-source evidence
- **MODERATE** (25-50% multi-source): Use caution with single-source claims
- **LOW** (<25% multi-source): Clearly indicate evidence strength

**Evidence Markers in Prompt:**
- üîµüî¥ = Multi-source evidence (Zep + OpenSearch) - HIGHEST CONFIDENCE
- üîµ = Semantic search only (Zep) - Good for conceptual understanding
- üî¥ = Keyword search only (OpenSearch) - Good for specific facts

### LLM Configuration (settings.yaml)

```yaml
llm:
  tasks:
    rag_answer_question:
      model: "gpt-4o"           # GPT-4 for reasoning with citations
      temperature: 0.2          # Low temperature for factual accuracy
      max_output_tokens: 2000   # Sufficient for comprehensive answers
      prompt_id: "rag_qa_v1"    # Question answering with hybrid retrieval
```

### Response Format

```json
{
  "query": "How do I hire A-players for my SaaS business?",
  "answer": "To hire A-players, focus on attitude over aptitude [1]. Use structured interviews with behavioral questions [2]...",
  "citations": [
    {
      "citation_number": 1,
      "chunk_id": "vid1_chunk_1",
      "video_id": "vid1",
      "video_title": "Hiring Best Practices",
      "source_type": "multi_source"
    }
  ],
  "evidence_quality": {
    "confidence": "high",
    "limitations": "None identified",
    "multi_source_count": 3,
    "total_chunks_used": 10,
    "confidence_ratio": 0.30
  },
  "retrieval_metadata": {
    "sources_queried": {"zep": true, "opensearch": true},
    "source_counts": {"zep": 15, "opensearch": 18},
    "weights": {"semantic": 0.6, "keyword": 0.4},
    "total_retrieved": 20,
    "total_used": 10
  },
  "context_balance": {
    "zep_tokens": 3500,
    "opensearch_tokens": 3200,
    "multi_source_tokens": 1200,
    "max_tokens_per_source": 4000
  },
  "llm_metadata": {
    "model": "gpt-4o",
    "prompt_id": "rag_qa_v1",
    "temperature": 0.2,
    "token_usage": {
      "input_tokens": 1500,
      "output_tokens": 300,
      "total_tokens": 1800
    }
  },
  "status": "success"
}
```

### Key Implementation Details

#### Context Balancing (lines 85-130)
Prevents single-source bias by enforcing token limits per source:
- Tracks tokens separately for Zep-only, OpenSearch-only, and multi-source chunks
- Multi-source evidence gets priority (counts towards both sources)
- Skips chunks when per-source limit would be exceeded
- Sorts by RRF score (highest first) before balancing

#### Evidence Alignment (lines 132-166)
Detects chunks appearing in both sources for high confidence:
- Counts multi-source, Zep-only, and OpenSearch-only chunks
- Calculates confidence ratio (multi-source / total chunks)
- Returns list of high-confidence chunk IDs
- Used to guide LLM trust hierarchy

#### Conflict Resolution (lines 168-193)
Applies deterministic trust hierarchy:
- HIGH: ‚â•50% multi-source ‚Üí "Prioritize multi-source evidence"
- MODERATE: 25-50% multi-source ‚Üí "Use caution with single-source claims"
- LOW: <25% multi-source ‚Üí "Clearly indicate evidence strength"

#### Prompt Construction (lines 195-240)
Builds comprehensive prompt with:
- Question clearly stated
- Evidence quality assessment (trust guidance)
- Confidence markers (üîµüî¥, üîµ, üî¥) for each chunk
- Full context with video titles, chunk IDs, RRF scores, sources
- Detailed instructions for citation and reasoning

#### Structured Outputs (lines 290-320)
Enforces strict JSON schema:
- answer: Comprehensive answer with inline citations [n]
- citations: Array with citation_number, chunk_id, video_id, video_title, source_type
- confidence: Enum ("high", "moderate", "low")
- limitations: String describing evidence gaps
- Schema enforced by OpenAI (no parsing errors)

### Low-Level Steps Implementation Status

1. ‚úÖ **Inputs**: query, filters (channel_id, dates), top_k, max_tokens_per_source
2. ‚úÖ **Call hybrid_retrieval**: Trim/dedupe context, balance per-source contributions
3. ‚úÖ **Evidence alignment**: Highlight overlaps with confidence markers
4. ‚úÖ **Conflict resolution**: Trust hierarchy and deterministic rules (multi-source > semantic > keyword)
5. ‚úÖ **Invoke LLM**: Structured outputs with schema enforcement
6. ‚úÖ **Return JSON**: Answer, citations, metrics

## ‚úÖ Acceptance Criteria

1. ‚úÖ **Returns valid JSON**: With answer, citations, and metrics
2. ‚úÖ **Handles conflicting signals**: Deterministic trust hierarchy based on evidence overlap
3. ‚úÖ **Context balancing**: Prevents single-source bias (max tokens per source)
4. ‚úÖ **Structured outputs**: OpenAI JSON schema enforcement (no parsing errors)
5. ‚úÖ **Citation tracking**: Complete with video titles and source types

## ‚úÖ Testing Strategy (Implemented)

**Test File**: `tests/summarizer_tools/test_answer_with_hybrid_context_coverage.py` (14 tests, 600+ lines)

**Coverage:**
1. ‚úÖ Successful answer generation with citations
2. ‚úÖ Missing OPENAI_API_KEY error handling
3. ‚úÖ Retrieval failure handling
4. ‚úÖ No results from retrieval
5. ‚úÖ Token estimation accuracy
6. ‚úÖ Context balancing per source
7. ‚úÖ Context balancing prevents overflow
8. ‚úÖ Evidence overlap detection
9. ‚úÖ Trust hierarchy conflict resolution (high/moderate/low confidence)
10. ‚úÖ Prompt construction with markers
11. ‚úÖ Structured output schema enforcement
12. ‚úÖ Channel filter passed to retrieval
13. ‚úÖ Date filters passed to retrieval
14. ‚úÖ General exception handling

**Mock Strategy:**
- Mock HybridRetrieval responses
- Mock OpenAI client and structured outputs
- Test alignment/trim logic with sample chunks
- Test JSON schema adherence with response validation

## üéØ Production Status

**READY FOR PRODUCTION**

### Prerequisites

1. **Environment Variables**:
   - `OPENAI_API_KEY`: Required for LLM calls
   - `ZEP_API_KEY` and/or `OPENSEARCH_HOST`: At least one search source

2. **Configuration** (`config/settings.yaml`):
   ```yaml
   llm:
     tasks:
       rag_answer_question:
         model: "gpt-4o"
         temperature: 0.2
         max_output_tokens: 2000
         prompt_id: "rag_qa_v1"
   ```

3. **Dependencies**:
   - HybridRetrieval tool must be operational
   - Transcripts indexed in Zep and/or OpenSearch

### Usage Example

```python
from answer_with_hybrid_context import AnswerWithHybridContext

# Basic usage
tool = AnswerWithHybridContext(
    query="How do I hire A-players for my SaaS business?",
    top_k=10,
    max_tokens_per_source=4000
)
result = tool.run()

# With filters
tool = AnswerWithHybridContext(
    query="What are the best pricing strategies?",
    top_k=5,
    max_tokens_per_source=3000,
    channel_id="UCkP5J0pXI11VE81q7S7V1Jw",
    min_published_date="2025-01-01T00:00:00Z"
)
result = tool.run()
```

### Integration Points

1. **HybridRetrieval**: Calls tool directly for fused results
2. **OpenAI**: Uses structured outputs with JSON schema enforcement
3. **Configuration**: Loads settings from `config/settings.yaml`
4. **Environment**: Respects OPENAI_API_KEY and search source configs

## üìù Summary

**Status**: ‚úÖ Fully implemented and production-ready

**Core Functionality**: ‚úÖ Complete
- Hybrid retrieval integration (Zep + OpenSearch)
- Context balancing (prevent bias)
- Evidence alignment (multi-source detection)
- Trust hierarchy (conflict resolution)
- Structured outputs (JSON schema enforced)
- Comprehensive citations and quality metrics

**Spec Compliance**: ‚úÖ All requirements met
- Inputs: query, filters, top_k, max_tokens_per_source
- Context balancing and per-source contributions
- Evidence alignment with overlap highlighting
- Conflict resolution using deterministic trust hierarchy
- LLM invocation with structured outputs
- JSON response with answer, citations, and metrics

**Recommendation**: Production-ready for RAG-powered Q&A with comprehensive evidence tracking and quality assessment.
