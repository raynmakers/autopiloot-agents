# Autopiloot Configuration File
# Runtime settings for orchestrator, scraper, transcriber, summarizer, observability, and linkedin agents

# Modular Agent Configuration
enabled_agents:
  - "orchestrator_agent"  # Required: CEO agent coordinates all workflows
  - "scraper_agent"       # YouTube content discovery
  - "transcriber_agent"   # Video transcription via AssemblyAI
  - "summarizer_agent"    # Business-focused summarization
  - "observability_agent" # Monitoring and notifications
  - "linkedin_agent"      # LinkedIn content ingestion
  - "strategy_agent"      # Strategic analysis and playbooks
  - "drive_agent"         # Google Drive content tracking

# Communication flows between agents (source -> target)
communication_flows:
  # CEO (orchestrator) coordinates all other agents
  - ["orchestrator_agent", "scraper_agent"]
  - ["orchestrator_agent", "transcriber_agent"]
  - ["orchestrator_agent", "summarizer_agent"]
  - ["orchestrator_agent", "linkedin_agent"]
  - ["orchestrator_agent", "strategy_agent"]
  - ["orchestrator_agent", "drive_agent"]
  - ["orchestrator_agent", "observability_agent"]

  # Primary content processing workflow
  - ["scraper_agent", "transcriber_agent"]      # Discovered videos -> transcription
  - ["transcriber_agent", "summarizer_agent"]   # Transcripts -> summaries

  # LinkedIn content analysis workflow
  - ["linkedin_agent", "strategy_agent"]        # LinkedIn content -> strategic analysis

  # Observability monitoring (bidirectional)
  - ["observability_agent", "scraper_agent"]
  - ["observability_agent", "transcriber_agent"]
  - ["observability_agent", "summarizer_agent"]
  - ["observability_agent", "linkedin_agent"]
  - ["observability_agent", "strategy_agent"]
  - ["observability_agent", "drive_agent"]

  # Error reporting and status updates back to observability
  - ["scraper_agent", "observability_agent"]
  - ["transcriber_agent", "observability_agent"]
  - ["summarizer_agent", "observability_agent"]
  - ["linkedin_agent", "observability_agent"]
  - ["strategy_agent", "observability_agent"]
  - ["drive_agent", "observability_agent"]

# ID of the Google Sheet used for backfill links
sheet: "1ikj9GU4_LG-q4i0ACsgrJ8BECX_YW-ujfr4kKWlJt8A"

scraper:
  handles:
    - "@AlexHormozi"
    - "@danmartell"
    - "@KimPerell"
  daily_limit_per_channel: 10
  page_size: 50  # Maximum number of videos to return per page (1-50)

sheets:
  daily_limit_per_channel: 10
  range_a1: "Sheet1!A:D"

llm:
  tasks:
    # Summarizer Agent Tasks
    summarizer_generate_short:
      model: "o3-mini"  # GPT-5 reasoning model
      temperature: 1.0  # High reasoning mode
      max_output_tokens: 50000  # No practical limit
      reasoning_effort: "high"  # Maximum reasoning
      prompt_id: "comprehensive_coach_v2"
      prompt_version: "v2"

    # Strategy Agent Tasks
    strategy_analyze_tone:
      model: "gpt-4o"
      temperature: 0.1
      max_output_tokens: 500
      prompt_id: "tone_analysis_v1"

    strategy_classify_posts:
      model: "gpt-4o"
      temperature: 0.1
      max_output_tokens: 1000
      prompt_id: "post_classification_v1"

    strategy_synthesize_playbook:
      model: "gpt-4o"
      temperature: 0.3
      max_output_tokens: 800
      prompt_id: "playbook_synthesis_v1"

    strategy_generate_briefs:
      model: "gpt-4o"
      temperature: 0.7
      max_output_tokens: 1000
      prompt_id: "content_briefs_v1"

    strategy_cluster_topics:
      embedding_model: "text-embedding-3-small"
      clustering_method: "kmeans"
      prompt_id: "topic_clustering_v1"

notifications:
  slack:
    channel: "ops-autopiloot"
    digest:
      enabled: true
      time: "07:00"
      timezone: "Europe/Amsterdam"
      channel: "ops-autopiloot"
      sections:
        - "summary"
        - "budgets"
        - "issues"
        - "links"

budgets:
  transcription_daily_usd: 5.0
  alert_threshold: 0.8  # 80% threshold for budget alerts

idempotency:
  max_video_duration_sec: 4200  # 70 minutes maximum
  status_progression:
    - "discovered"
    - "transcribed" 
    - "summarized"
  drive_naming_format: "{video_id}_{date}_{type}.{ext}"

reliability:
  retry:
    max_attempts: 3  # Maximum retry attempts before DLQ
    base_delay_sec: 60  # Base delay for exponential backoff in seconds
  quotas:
    youtube_daily_limit: 10000  # YouTube Data API daily quota
    assemblyai_daily_limit: 100  # AssemblyAI daily transcription limit

orchestrator:
  parallelism:
    max_parallel_jobs: 5  # Maximum concurrent jobs across all agents
    max_dispatch_batch: 10  # Maximum items per batch dispatch
  coordination:
    run_timeout_minutes: 120  # Maximum runtime for daily runs
    dlq_escalation_threshold: 5  # DLQ items before escalation
  policies:
    budget_enforcement: true  # Enable budget limit enforcement
    quota_enforcement: true  # Enable API quota enforcement
    max_retries_per_video: 3  # Global retry limit per video

rapidapi:
  # Centralized RapidAPI plugin configuration
  # Each plugin has its own host and API key
  # Multiple tools can reference the same plugin
  plugins:
    linkedin_scraper:
      host: "fresh-linkedin-scraper-api.p.rapidapi.com"
      api_key_env: "RAPIDAPI_LINKEDIN_SCRAPER_KEY"  # References env var in .env
      endpoints:
        user_posts: "/api/v1/user/posts"
        user_profile: "/api/v1/user/profile"
        user_comments: "/api/v1/user/comments"
        post_comments: "/api/v1/post/comments"
        post_comment_replies: "/api/v1/post/comments/replies"
        post_reactions: "/api/v1/post/reactions"
        post_reposts: "/api/v1/post/reposts"
    # Add more plugins as needed:
    # example_plugin:
    #   host: "another-api.p.rapidapi.com"
    #   api_key_env: "RAPIDAPI_EXAMPLE_KEY"

summarizer:
  zep:
    # Zep v3 Architecture (Threads API via HTTP - no SDK due to Python 3.13 incompatibility)
    # - Users: Represent YouTube channels (user_id = channel_handle without @, lowercase)
    # - Threads: Represent individual videos (thread_id = "summary_{video_id}")
    # - Messages: Contain summary content with metadata
    # - Knowledge Graph: Zep automatically builds from message content
    enabled: true
    api_version: "v3"  # Using Threads API with direct HTTP calls
    user_id_format: "channel_handle_lowercase"  # e.g., "@DanMartell" -> "danmartell"
    thread_id_format: "summary_{video_id}"  # e.g., "summary_mZxDw92UXmA"

linkedin:
  api:
    # RapidAPI configuration is in rapidapi.plugins.linkedin_scraper section
    rate_limit_per_minute: 60  # Rate limiting for LinkedIn API calls
    max_posts_per_profile: 50  # Maximum posts to fetch per profile
    rapidapi_plugin: "linkedin_scraper"  # References rapidapi.plugins.linkedin_scraper
  profiles:
    # Target LinkedIn profiles for content ingestion
    - "alexhormozi"  # Example LinkedIn username/handle
  zep:
    group_prefix: "linkedin"  # Prefix for Zep group names (e.g., "linkedin_posts", "linkedin_comments")
    collection_name: "linkedin_content"  # Zep collection for LinkedIn content
  processing:
    daily_limit_per_profile: 25  # Maximum content items per profile per day
    content_types:
      - "posts"
      - "comments"
      - "reactions"
    min_engagement_threshold: 5  # Minimum likes/comments to process content

drive:
  tracking:
    # Configured Drive files and folders to track for content changes
    targets:
      # Example folder configuration
      - type: "folder"
        id: "example_folder_id_here"
        recursive: true
        name: "Strategy Documents"
      # Example file configuration
      - type: "file"
        id: "example_file_id_here"
        name: "Playbook.docx"
    sync_interval_minutes: 60  # How often to check for changes
    max_file_size_mb: 10  # Maximum file size to process
    supported_formats:
      - ".txt"
      - ".md"
      - ".pdf"
      - ".docx"
      - ".html"
      - ".csv"

rag:
  zep:
    namespace:
      drive: "autopiloot-dev"  # Zep namespace for Drive content indexing

  opensearch:
    # OpenSearch configuration for keyword/boolean retrieval in Hybrid RAG
    # Used alongside Zep for semantic + keyword search combination
    enabled: true
    host: ""  # Set via OPENSEARCH_HOST environment variable
    index_transcripts: "autopiloot_transcripts"  # Index name for transcript storage
    top_k: 20  # Number of results to retrieve from OpenSearch
    timeout_ms: 1500  # Request timeout in milliseconds
    weights:
      # Hybrid search weights (must sum to 1.0)
      semantic: 0.6  # Weight for semantic (vector) search results
      keyword: 0.4   # Weight for keyword (BM25) search results
    connection:
      # Connection settings
      verify_certs: true  # Verify SSL certificates
      use_ssl: true       # Use SSL/TLS for connections
      max_retries: 3      # Maximum number of retry attempts
      retry_on_timeout: true  # Retry on timeout errors

